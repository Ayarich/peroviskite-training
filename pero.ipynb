{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e420cace-5263-4c9b-b020-78547b109af5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, f1_score\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from tensorflow.keras.models import Sequential  # type: ignore\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten # type: ignore\n",
        "from tensorflow.keras.optimizers import Adam # type: ignore\n",
        "import tensorflow as tf\n",
        "\n",
        "# Force CPU usage\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "# ===============================\n",
        "# Helper Functions\n",
        "# ===============================\n",
        "\n",
        "def clean_numeric_string(numeric_str):\n",
        "    \"\"\"Cleans numeric-like strings and returns mean if multiple values.\"\"\"\n",
        "    if pd.isna(numeric_str) or not isinstance(numeric_str, str):\n",
        "        return numeric_str\n",
        "    temp_str = numeric_str.strip().replace(' | ', ';').replace(' >> ', ';').replace(' ', '').replace(':', ';')\n",
        "    parts = temp_str.split(';')\n",
        "    temps = []\n",
        "    for p in parts:\n",
        "        p_cleaned = p.strip()\n",
        "        p_cleaned = p_cleaned.replace('%', '').replace('mol%', '').replace('mg/ml', '').replace('uL', '').replace('mM', '').replace('vol%', '')\n",
        "        try:\n",
        "            if p_cleaned and p_cleaned.replace('.', '', 1).isdigit():\n",
        "                temps.append(float(p_cleaned))\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return np.mean(temps) if temps else np.nan\n",
        "\n",
        "def preprocess_dataframe(df, target_col='Stability_PCE_T80'):\n",
        "    \"\"\"Preprocess a single dataframe (NIP or PIN) independently.\"\"\"\n",
        "    missing_value_strings = ['unknown', 'nan', 'na', 'none', 'n/a', 'not available', '', ' ']\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.strip().str.lower().replace(missing_value_strings, np.nan)\n",
        "\n",
        "    threshold = 0.70\n",
        "    missing_percentages = df.isnull().sum() / len(df)\n",
        "    cols_to_drop = missing_percentages[missing_percentages >= threshold].index.tolist()\n",
        "    if target_col in cols_to_drop:\n",
        "        cols_to_drop.remove(target_col)\n",
        "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    numeric_columns_to_clean = [\n",
        "        'Cell_area_measured', 'ETL_thickness', 'Perovskite_composition_a_ions_coefficients',\n",
        "        'Perovskite_composition_b_ions_coefficients', 'Perovskite_composition_c_ions_coefficients',\n",
        "        'Perovskite_thickness', 'Perovskite_band_gap', 'Perovskite_deposition_thermal_annealing_temperature',\n",
        "        'Perovskite_deposition_thermal_annealing_time', 'Backcontact_thickness_list',\n",
        "        'Stability_potential_bias_range', 'Stability_temperature_range',\n",
        "        'JV_default_Voc', 'JV_default_Jsc', 'JV_default_FF', 'JV_default_PCE'\n",
        "    ]\n",
        "    for col in numeric_columns_to_clean:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(clean_numeric_string)\n",
        "\n",
        "    boolean_columns_to_convert = [\n",
        "        'Perovskite_single_crystal', 'Perovskite_dimension_0D', 'Perovskite_dimension_2D',\n",
        "        'Perovskite_dimension_2D3D_mixture', 'Perovskite_dimension_3D_with_2D_capping_layer',\n",
        "        'Perovskite_composition_inorganic', 'Perovskite_composition_leadfree',\n",
        "        'Perovskite_deposition_quenching_induced_crystallisation', 'Perovskite_deposition_solvent_annealing',\n",
        "        'Add_lay_front', 'Add_lay_back', 'Encapsulation', 'Stability_light_UV_filter'\n",
        "    ]\n",
        "    for col in boolean_columns_to_convert:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.lower().replace({'true': 1, 'false': 0}).astype(float)\n",
        "    if 'Perovskite_dimension_3D' in df.columns:\n",
        "        df['Perovskite_dimension_3D'] = df['Perovskite_dimension_3D'].astype(float)\n",
        "\n",
        "    categorical_cols = [col for col in df.columns if df[col].dtype == 'object' and col != target_col]\n",
        "    if categorical_cols:\n",
        "        encoder = TargetEncoder(cols=categorical_cols)\n",
        "        encoder.fit(df[categorical_cols], df[target_col])\n",
        "        df_encoded_categorical = encoder.transform(df[categorical_cols])\n",
        "        non_categorical_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "        df = pd.concat([df[non_categorical_cols].reset_index(drop=True),\n",
        "                        df_encoded_categorical.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    for col in numeric_cols:\n",
        "        if col != target_col:\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    return df\n",
        "\n",
        "def plot_correlation_heatmap(df, prefix, target_col):\n",
        "    numeric_df = df.select_dtypes(include=np.number)\n",
        "    corr = numeric_df.corr()\n",
        "    target_corr = corr[[target_col]].sort_values(by=target_col, ascending=False)\n",
        "    target_corr.to_csv(f\"{prefix}_target_correlation.csv\")\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr, cmap=\"coolwarm\", annot=False, fmt=\".2f\", cbar=True)\n",
        "    plt.title(f\"{prefix} - Feature Correlation Heatmap\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{prefix}_heatmap.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def extract_feature_importance(model, X, prefix, task_type, model_name):\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        feature_importances = pd.DataFrame({\n",
        "            'Feature': X.columns,\n",
        "            'Importance': model.feature_importances_\n",
        "        }).sort_values(by=\"Importance\", ascending=False)\n",
        "        feature_importances.to_csv(f\"{prefix}_{model_name}_{task_type}_feature_importance.csv\", index=False)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importances.head(15), palette=\"viridis\")\n",
        "        plt.title(f\"{prefix} - Top 15 Features ({model_name} {task_type})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{prefix}_{model_name}_{task_type}_feature_importance.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "def build_ann(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_dim):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(input_dim, 1)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "def train_and_save_models(df, target_col, prefix, metrics_list):\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    y_class = (y >= y.median()).astype(int)\n",
        "    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
        "\n",
        "    # ======= Add these conversions to fix dtype issues =======\n",
        "    # Convert all to numeric numpy arrays with float32 dtype\n",
        "    X_train = X_train.astype(np.float32).to_numpy()\n",
        "    X_test = X_test.astype(np.float32).to_numpy()\n",
        "    y_train = y_train.astype(np.float32).to_numpy()\n",
        "    y_test = y_test.astype(np.float32).to_numpy()\n",
        "\n",
        "    X_train_c = X_train_c.astype(np.float32).to_numpy()\n",
        "    X_test_c = X_test_c.astype(np.float32).to_numpy()\n",
        "    y_train_c = y_train_c.astype(np.float32).to_numpy()\n",
        "    y_test_c = y_test_c.astype(np.float32).to_numpy()\n",
        "    # ==========================================================\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "    # Rest of your code unchanged ...\n",
        "\n",
        "    # Models to train\n",
        "    models = {\n",
        "        \"RF\": (RandomForestRegressor(random_state=42), RandomForestClassifier(random_state=42)),\n",
        "        \"XGB\": (XGBRegressor(random_state=42, n_jobs=-1), XGBClassifier(random_state=42, n_jobs=-1)),\n",
        "    }\n",
        "\n",
        "    for name, (reg_model, clf_model) in models.items():\n",
        "        # Regression\n",
        "        reg_model.fit(X_train, y_train)\n",
        "        y_pred = reg_model.predict(X_test)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        metrics_list.append([prefix, name, \"Regression\", r2_score(y_test, y_pred), rmse, None, None])\n",
        "        extract_feature_importance(reg_model, X, prefix, \"regression\", name)\n",
        "        joblib.dump(reg_model, f\"models/{prefix}_{name}_regression.joblib\")\n",
        "\n",
        "        # Classification\n",
        "        clf_model.fit(X_train_c, y_train_c)\n",
        "        y_pred_c = clf_model.predict(X_test_c)\n",
        "        metrics_list.append([prefix, name, \"Classification\", None, None, accuracy_score(y_test_c, y_pred_c), f1_score(y_test_c, y_pred_c)])\n",
        "        extract_feature_importance(clf_model, X, prefix, \"classification\", name)\n",
        "        joblib.dump(clf_model, f\"models/{prefix}_{name}_classification.joblib\")\n",
        "\n",
        "    # ANN Regression\n",
        "    ann = build_ann(X_train.shape[1])\n",
        "    ann.fit(X_train, y_train, epochs=30, batch_size=16, verbose=0)\n",
        "    y_pred_ann = ann.predict(X_test).flatten()\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_ann))\n",
        "    metrics_list.append([prefix, \"ANN\", \"Regression\", r2_score(y_test, y_pred_ann), rmse, None, None])\n",
        "    ann.save(f\"models/{prefix}_ANN_regression.h5\")\n",
        "\n",
        "    # ANN Classification\n",
        "    ann_c = build_ann(X_train_c.shape[1])\n",
        "    ann_c.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    ann_c.fit(X_train_c, y_train_c, epochs=30, batch_size=16, verbose=0)\n",
        "    y_pred_ann_c = (ann_c.predict(X_test_c) >= 0.5).astype(int)\n",
        "    metrics_list.append([prefix, \"ANN\", \"Classification\", None, None, accuracy_score(y_test_c, y_pred_ann_c), f1_score(y_test_c, y_pred_ann_c)])\n",
        "    ann_c.save(f\"models/{prefix}_ANN_classification.h5\")\n",
        "\n",
        "    # CNN Regression\n",
        "    cnn = build_cnn(X_train.shape[1])\n",
        "    cnn.fit(np.expand_dims(X_train, axis=2), y_train, epochs=30, batch_size=16, verbose=0)\n",
        "    y_pred_cnn = cnn.predict(np.expand_dims(X_test, axis=2)).flatten()\n",
        "    metrics_list.append([prefix, \"CNN\", \"Regression\", r2_score(y_test, y_pred_cnn), np.sqrt(mean_squared_error(y_test, y_pred_cnn)), None, None])\n",
        "    cnn.save(f\"models/{prefix}_CNN_regression.h5\")\n",
        "\n",
        "    # CNN Classification\n",
        "    cnn_c = build_cnn(X_train_c.shape[1])\n",
        "    cnn_c.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    cnn_c.fit(np.expand_dims(X_train_c, axis=2), y_train_c, epochs=30, batch_size=16, verbose=0)\n",
        "    y_pred_cnn_c = (cnn_c.predict(np.expand_dims(X_test_c, axis=2)) >= 0.5).astype(int)\n",
        "    metrics_list.append([prefix, \"CNN\", \"Classification\", None, None, accuracy_score(y_test_c, y_pred_cnn_c), f1_score(y_test_c, y_pred_cnn_c)])\n",
        "    cnn_c.save(f\"models/{prefix}_CNN_classification.h5\")\n",
        "\n",
        "# ===============================\n",
        "# Main Script\n",
        "# ===============================\n",
        "dtype_spec = {\n",
        "    'Substrate_thickness': 'object',\n",
        "    'Perovskite_single_crystal': 'object',\n",
        "    'JV_default_PCE': 'object'\n",
        "}\n",
        "df = pd.read_csv(\"Perovskite_database.csv\", dtype=dtype_spec)\n",
        "df = df.dropna(subset=['Stability_PCE_T80'])\n",
        "\n",
        "df_nip = df[df['Cell_architecture'] == 'nip'].copy()\n",
        "df_pin = df[df['Cell_architecture'] == 'pin'].copy()\n",
        "\n",
        "df_nip_cleaned = preprocess_dataframe(df_nip)\n",
        "df_pin_cleaned = preprocess_dataframe(df_pin)\n",
        "\n",
        "plot_correlation_heatmap(df_nip_cleaned, \"NIP\", \"Stability_PCE_T80\")\n",
        "plot_correlation_heatmap(df_pin_cleaned, \"PIN\", \"Stability_PCE_T80\")\n",
        "\n",
        "df_nip_cleaned.to_csv(\"Perovskite_NIP_cleaned.csv\", index=False)\n",
        "df_pin_cleaned.to_csv(\"Perovskite_PIN_cleaned.csv\", index=False)\n",
        "\n",
        "metrics = []\n",
        "train_and_save_models(df_nip_cleaned, 'Stability_PCE_T80', \"NIP\", metrics)\n",
        "train_and_save_models(df_pin_cleaned, 'Stability_PCE_T80', \"PIN\", metrics)\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics, columns=[\"Architecture\", \"Model\", \"Task\", \"R2\", \"RMSE\", \"Accuracy\", \"F1\"])\n",
        "metrics_df.to_csv(\"model_performance_summary.csv\", index=False)\n",
        "print(metrics_df)\n",
        "\n",
        "\n",
        "\n",
        "# Show top 5 regression models\n",
        "print(\"\\nTop 5 Regression Models:\")\n",
        "top_reg = metrics_df.dropna(subset=[\"R2\"]).sort_values(by=\"R2\", ascending=False).head(5)\n",
        "print(top_reg)\n",
        "\n",
        "# Show top 5 classification models\n",
        "print(\"\\nTop 5 Classification Models:\")\n",
        "top_clf = metrics_df.dropna(subset=[\"F1\"]).sort_values(by=\"F1\", ascending=False).head(5)\n",
        "print(top_clf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b85b3a0-06c0-4698-88c3-8d6190a7ec97",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
